{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Centre Department - Predictive Analysis\n",
    "\n",
    "Analyzing through various concepts of forecasting for No. of Calls Offered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../Data/Call Centre Dept/Call_Centre_CLEANED_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting with Time Series Model for Calls Offered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disect data of Date and Calls Offered ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_off_df = df[['Date', 'Calls_Offered']]\n",
    "call_off_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null values\n",
    "call_off_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check info\n",
    "call_off_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test to fix SARIMA\n",
    "call_off_df = call_off_df.replace(np.inf, np.nan).replace(-np.inf, np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change 'Date' column to datetime\n",
    "call_off_df['Date'] = pd.to_datetime(call_off_df['Date'], infer_datetime_format=True)\n",
    "#Set as index\n",
    "call_off_df = call_off_df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the proper time period for weekly aggregation\n",
    "call_off_df = call_off_df['2021-01-01':'2021-12-31'].resample('W').sum()\n",
    "call_off_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_off_df.loc['2021-06-25':'2021-07-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groupby Date to show Year/Month --> Summarize Calls_Offered\n",
    "#call_off_df_mth = call_off_df.groupby(call_off_df.Date.dt.to_period('M')).agg('sum')\n",
    "#call_off_df_mth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative to find Date and Time\n",
    "\n",
    "#Normalize Day of Month\n",
    "#call_off_df['Year_Month'] = call_off_df['Date'] + pd.offsets.MonthEnd(-1) + pd.offsets.Day(1)\n",
    "\n",
    "#Groupby by Month -> Summarize Calls Offered\n",
    "#call_off_df.groupby('Year_Month')['Calls_Offered'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Common Time Series Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the Data\n",
    "y = call_off_df['Calls_Offered']\n",
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "\n",
    "ax.plot(y, marker='.', linestyle='-', linewidth=0.5, label='Weekly')\n",
    "ax.plot(y.resample('M').mean(), marker='o', markersize=8, linestyle='-', label='Monthly Mean Resample')\n",
    "ax.set_ylabel('Calls Offered')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decompose Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphs to show seasonal_decompose \n",
    "#max period is round down(53/2) \n",
    "def seasonal_decompose(y):\n",
    "    decomposition = sm.tsa.seasonal_decompose(y, model='additive', extrapolate_trend='freq', period=7)\n",
    "    fig = decomposition.plot()\n",
    "    fig.set_size_inches(14,7)\n",
    "    plt.show()\n",
    "\n",
    "seasonal_decompose(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot for Rolling Statistic to test Stationarity\n",
    "def test_stationarity(timeseries, title):\n",
    "\n",
    "    #Determine rolling statistics\n",
    "    rolmean = pd.Series(timeseries).rolling(window=12).mean()\n",
    "    rolstd = pd.Series(timeseries).rolling(window=12).std()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(16, 4))\n",
    "    ax.plot(timeseries, label= title)\n",
    "    ax.plot(rolmean, label='rolling mean')\n",
    "    ax.plot(rolstd, label='rolling std (x10)')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.8f}'.format\n",
    "test_stationarity(y, 'raw data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above, it does not seems like it is stationary. However, let's look at performing another test of stationarity to further evaluate it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented Dickey-Fuller Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmented Dickey-Fuller Test\n",
    "def ADF_test(timeseries, dataDesc):\n",
    "    print(' > Is the {} stationary ?'.format(dataDesc))\n",
    "    dftest = adfuller(timeseries.dropna(), autolag='AIC')\n",
    "    print('Test statistic = {:.3f}'.format(dftest[0]))\n",
    "    print('P-value = {:.3f}'.format(dftest[1]))\n",
    "    print('Critical values :')\n",
    "    for k, v in dftest[4].items():\n",
    "        print('\\t{}: {} - The data is {} stationary with {}% confidence'.format(k, v, 'not' if v<dftest[0] else '', 100-int(k[:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADF_test(y, 'raw data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As based on the 1%: Data is not stationary within 99 percent of the confidence interval. Hence, there is a need to stationarize the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the Data Stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detrending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detrend\n",
    "y_detrend = (y - y.rolling(window=12).mean())/y.rolling(window=12).std()\n",
    "\n",
    "test_stationarity(y_detrend,'de-trended data')\n",
    "ADF_test(y_detrend,'de-trended data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#differencing\n",
    "y_12lag = y - y.shift(12)\n",
    "\n",
    "test_stationarity(y_12lag,'12 lag differenced data')\n",
    "ADF_test(y_12lag,'12 lag differenced data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the differencing provides the best results, this will be the transformation that will be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Detrending and Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detrend + differencing\n",
    "#y_12lag_detrend = y_detrend - y_detrend.shift(12)\n",
    "#\n",
    "#test_stationarity(y_12lag_detrend,'12 lag differenced de-trended data')\n",
    "#ADF_test(y_12lag_detrend,'12 lag differenced de-trended data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training & Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set y_to_train, y_to_test, and the length of predict units\n",
    "y_to_train = y[:'2021-06-30'] #dataset to train\n",
    "y_to_test = y['2021-07-01':] #last X months for test\n",
    "\n",
    "predict_date = len(y) - len(y[:'2021-06-30']) # the number of data points for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Exponential Smoothing (SES)\n",
    "\n",
    "Suitable for time series data without trend or seasonal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ses(y, y_to_train,y_to_test,smoothing_level,predict_date):\n",
    "    y.plot(marker='o', color='black', legend=True, figsize=(14, 7))\n",
    "    \n",
    "    fit1 = SimpleExpSmoothing(y_to_train).fit(smoothing_level=smoothing_level,optimized=False)\n",
    "    fcast1 = fit1.forecast(predict_date).rename(r'$\\alpha={}$'.format(smoothing_level))\n",
    "    # specific smoothing level\n",
    "    fcast1.plot(marker='o', color='blue', legend=True)\n",
    "    fit1.fittedvalues.plot(marker='o',  color='blue')\n",
    "    mse1 = ((fcast1 - y_to_test) ** 2).mean()\n",
    "    print('The Root Mean Squared Error of our forecasts with smoothing level of {} is {}'.format(smoothing_level,round(np.sqrt(mse1), 2)))\n",
    "    \n",
    "    ## auto optimization\n",
    "    fit2 = SimpleExpSmoothing(y_to_train).fit()\n",
    "    fcast2 = fit2.forecast(predict_date).rename(r'$\\alpha=%s$'%fit2.model.params['smoothing_level'])\n",
    "    # plot\n",
    "    fcast2.plot(marker='o', color='green', legend=True)\n",
    "    fit2.fittedvalues.plot(marker='o', color='green')\n",
    "    \n",
    "    mse2 = ((fcast2 - y_to_test) ** 2).mean()\n",
    "    print('The Root Mean Squared Error of our forecasts with auto optimization is {}'.format(round(np.sqrt(mse2), 2)))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses(y, y_to_train,y_to_test,0.8,predict_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the visualization results from SES, it is not ideal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holt's Linear Trend Method\n",
    "\n",
    "Suitable for time series data with a trend component but without a seasonal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import Holt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#holt's linear trend\n",
    "def holt(y,y_to_train,y_to_test,smoothing_level,smoothing_slope, predict_date):\n",
    "    y.plot(marker='o', color='black', legend=True, figsize=(14, 7))\n",
    "    \n",
    "    fit1 = Holt(y_to_train).fit(smoothing_level, smoothing_slope, optimized=False)\n",
    "    fcast1 = fit1.forecast(predict_date).rename(\"Holt's linear trend\")\n",
    "    mse1 = ((fcast1 - y_to_test) ** 2).mean()\n",
    "    print('The Root Mean Squared Error of Holt''s Linear trend {}'.format(round(np.sqrt(mse1), 2)))\n",
    "\n",
    "    fit2 = Holt(y_to_train, exponential=True).fit(smoothing_level, smoothing_slope, optimized=False)\n",
    "    fcast2 = fit2.forecast(predict_date).rename(\"Exponential trend\")\n",
    "    mse2 = ((fcast2 - y_to_test) ** 2).mean()\n",
    "    print('The Root Mean Squared Error of Holt''s Exponential trend {}'.format(round(np.sqrt(mse2), 2)))\n",
    "    \n",
    "    fit3 = Holt(y_to_train, damped_trend=True).fit(smoothing_level, smoothing_slope)\n",
    "    fcast3 = fit3.forecast(predict_date).rename(\"Additive damped trend\")\n",
    "    mse3 = ((fcast3 - y_to_test) ** 2).mean()\n",
    "    print('The Root Mean Squared Error of Holt''s Additive damped trend {}'.format(round(np.sqrt(mse2), 2)))\n",
    "\n",
    "    fit1.fittedvalues.plot(marker=\"o\", color='blue')\n",
    "    fcast1.plot(color='blue', marker=\"o\", legend=True)\n",
    "    fit2.fittedvalues.plot(marker=\"o\", color='red')\n",
    "    fcast2.plot(color='red', marker=\"o\", legend=True)\n",
    "    fit3.fittedvalues.plot(marker=\"o\", color='green')\n",
    "    fcast3.plot(color='green', marker=\"o\", legend=True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holt(y, y_to_train,y_to_test,0.6,0.2,predict_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMA\n",
    "\n",
    "Suitable for time series data with trend and/or seasonal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sarima \n",
    "def sarima_grid_search(y,seasonal_period):\n",
    "    p = d = q = range(0, 2)\n",
    "    pdq = list(itertools.product(p, d, q))\n",
    "    seasonal_pdq = [(x[0], x[1], x[2],seasonal_period) for x in list(itertools.product(p, d, q))]\n",
    "    \n",
    "    mini = float('+inf')\n",
    "    \n",
    "    \n",
    "    for param in pdq:\n",
    "        for param_seasonal in seasonal_pdq:\n",
    "            try:\n",
    "                mod = sm.tsa.statespace.SARIMAX(y,\n",
    "                                                order=param,\n",
    "                                                seasonal_order=param_seasonal,\n",
    "                                                enforce_stationarity=False,\n",
    "                                                enforce_invertibility=False)\n",
    "\n",
    "                results = mod.fit()\n",
    "                \n",
    "                if results.aic < mini:\n",
    "                    mini = results.aic\n",
    "                    param_mini = param\n",
    "                    param_seasonal_mini = param_seasonal\n",
    "\n",
    "#                 print('SARIMA{}x{} - AIC:{}'.format(param, param_seasonal, results.aic))\n",
    "            except:\n",
    "                continue\n",
    "    print('The set of parameters with the minimum AIC is: SARIMA{}x{} - AIC:{}'.format(param_mini, param_seasonal_mini, mini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_grid_search(y,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call this function after pick the right(p,d,q) for SARIMA based on AIC               \n",
    "def sarima_eva(y,order,seasonal_order,seasonal_period,pred_date,y_to_test):\n",
    "    # fit the model \n",
    "    mod = sm.tsa.statespace.SARIMAX(y,\n",
    "                                order=order,\n",
    "                                seasonal_order=seasonal_order,\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "\n",
    "    results = mod.fit()\n",
    "    print(results.summary().tables[1])\n",
    "    \n",
    "    results.plot_diagnostics(figsize=(16, 8))\n",
    "    plt.show()\n",
    "    \n",
    "    # The dynamic=False argument ensures that we produce one-step ahead forecasts, \n",
    "    # meaning that forecasts at each point are generated using the full history up to that point.\n",
    "    pred = results.get_prediction(start=pd.to_datetime(pred_date), dynamic=False)\n",
    "    pred_ci = pred.conf_int()\n",
    "    y_forecasted = pred.predicted_mean\n",
    "    mse = ((y_forecasted - y_to_test) ** 2).mean()\n",
    "    print('The Root Mean Squared Error of SARIMA with season_length={} and dynamic = False {}'.format(seasonal_period,round(np.sqrt(mse), 2)))\n",
    "\n",
    "    ax = y.plot(label='observed')\n",
    "    y_forecasted.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))\n",
    "    ax.fill_between(pred_ci.index,\n",
    "                    pred_ci.iloc[:, 0],\n",
    "                    pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Calls Offered')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # A better representation of our true predictive power can be obtained using dynamic forecasts. \n",
    "    # In this case, we only use information from the time series up to a certain point, \n",
    "    # and after that, forecasts are generated using values from previous forecasted time points.\n",
    "    pred_dynamic = results.get_prediction(start=pd.to_datetime(pred_date), dynamic=True, full_results=True)\n",
    "    pred_dynamic_ci = pred_dynamic.conf_int()\n",
    "    y_forecasted_dynamic = pred_dynamic.predicted_mean\n",
    "    mse_dynamic = ((y_forecasted_dynamic - y_to_test) ** 2).mean()\n",
    "    print('The Root Mean Squared Error of SARIMA with season_length={} and dynamic = True {}'.format(seasonal_period,round(np.sqrt(mse_dynamic), 2)))\n",
    "\n",
    "    ax = y.plot(label='observed')\n",
    "    y_forecasted_dynamic.plot(label='Dynamic Forecast', ax=ax,figsize=(14, 7))\n",
    "    ax.fill_between(pred_dynamic_ci.index,\n",
    "                    pred_dynamic_ci.iloc[:, 0],\n",
    "                    pred_dynamic_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Calls Offered')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of parameters with the minimum AIC is: SARIMA(0, 0, 0)x(0, 1, 0, 52) - AIC:2.0\n",
    "\n",
    "test w/ seasonal period 12: The set of parameters with the minimum AIC is: SARIMA(1, 1, 0)x(1, 1, 0, 12) - AIC:512.9419660646736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sarima_eva(y,(1,1,0),(1,1,0,12),12,'2021-07-04',y_to_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model,predict_steps,y):\n",
    "    \n",
    "    pred_uc = model.get_forecast(steps=predict_steps)\n",
    "\n",
    "    #SARIMAXResults.conf_int, can change alpha,the default alpha = .05 returns a 95% confidence interval.\n",
    "    pred_ci = pred_uc.conf_int()\n",
    "\n",
    "    ax = y.plot(label='observed', figsize=(14, 7))\n",
    "#     print(pred_uc.predicted_mean)\n",
    "    pred_uc.predicted_mean.plot(ax=ax, label='Forecast')\n",
    "    ax.fill_between(pred_ci.index,\n",
    "                    pred_ci.iloc[:, 0],\n",
    "                    pred_ci.iloc[:, 1], color='k', alpha=.25)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel(y.name)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Produce the forcasted tables \n",
    "    pm = pred_uc.predicted_mean.reset_index()\n",
    "    pm.columns = ['Date','Predicted_Mean']\n",
    "    pci = pred_ci.reset_index()\n",
    "    pci.columns = ['Date','Lower Bound','Upper Bound']\n",
    "    final_table = pm.join(pci.set_index('Date'), on='Date')\n",
    "    \n",
    "    return (final_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = forecast(model,52,y)\n",
    "final_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating SARIMA with MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each predicted data point, the absolute difference from the corresponding test point was calculated, and then divided by the test point. The average percentage gives the MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.tsa.statespace.SARIMAX(y,order = (1,1,0), \n",
    "                                seasonal_order= (1,1,0,12),\n",
    "                                seasonal_period= 12)\n",
    "results = mod.fit()\n",
    "print(results.summary().tables[1])\n",
    "    \n",
    "results.plot_diagnostics(figsize=(16, 8))\n",
    "#plt.show()\n",
    "\n",
    "    # The dynamic=False argument ensures that we produce one-step ahead forecasts, \n",
    "    # meaning that forecasts at each point are generated using the full history up to that point.\n",
    "pred = results.get_prediction(start=pd.to_datetime('2021-07-04'), dynamic=False)\n",
    "pred_ci = pred.conf_int()\n",
    "y_forecasted = pred.predicted_mean\n",
    "y_forecasted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_accuracy(forecast, actual):\n",
    "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # mean absolute percentage error\n",
    "    me = np.mean(forecast - actual)             # ME\n",
    "    mae = np.mean(np.abs(forecast - actual))    # mean absolute error\n",
    "    mpe = np.mean((forecast - actual)/actual)   # MPE\n",
    "    rmse = np.mean((forecast - actual)**2)**.5  # root mean square\n",
    "    corr = np.corrcoef(forecast, actual)[0,1]   # corr\n",
    "    mins = np.amin(np.hstack([forecast[:,None], actual[:,None]]), axis=1)\n",
    "    maxs = np.amax(np.hstack([forecast[:,None], actual[:,None]]), axis=1)\n",
    "    minmax = 1 - np.mean(mins/maxs)             # minmax\n",
    "    acf1 = acf(forecast-y_to_test)[1]                      # ACF1\n",
    "    return({'mape':mape, 'me':me, 'mae': mae, \n",
    "            'mpe': mpe, 'rmse':rmse, 'acf1':acf1,\n",
    "            'corr':corr, 'minmax':minmax})\n",
    "\n",
    "forecast_accuracy(y_forecasted, y_to_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Around 1.565% MAPE implies the model is about 97.75% accurate in predicting the next 28 observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA\n",
    "\n",
    "DOES NOT WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_off_df.head()\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Calls Offered')\n",
    "plt.plot(call_off_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for rolling mean and std\n",
    "rolling_mean = call_off_df.rolling(window = 12).mean()\n",
    "rolling_std = call_off_df.rolling(window = 12).std()\n",
    "plt.plot(call_off_df, color = 'blue', label = 'Original')\n",
    "plt.plot(rolling_mean, color = 'red', label = 'Rolling Mean')\n",
    "plt.plot(rolling_std, color = 'black', label = 'Rolling Std')\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Rolling Mean & Rolling Standard Deviation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for ADF and p-value\n",
    "result = adfuller(call_off_df['Calls_Offered'])\n",
    "print('ADF Statistic: {}'.format(result[0]))\n",
    "print('p-value: {}'.format(result[1]))\n",
    "print('Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "    print('\\t{}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As p-value is not <0.05 --> take log to lower the rate as rolling mean increases\n",
    "call_off_df_log = np.log(call_off_df)\n",
    "plt.plot(call_off_df_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for stationarity\n",
    "def get_stationarity(timeseries):\n",
    "    \n",
    "    # rolling statistics\n",
    "    rolling_mean = timeseries.rolling(window=12).mean()\n",
    "    rolling_std = timeseries.rolling(window=12).std()\n",
    "    \n",
    "    # rolling statistics plot\n",
    "    original = plt.plot(timeseries, color='blue', label='Original')\n",
    "    mean = plt.plot(rolling_mean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolling_std, color='black', label='Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    # Dickeyâ€“Fuller test:\n",
    "    result = adfuller(timeseries['Calls_Offered'])\n",
    "    print('ADF Statistic: {}'.format(result[0]))\n",
    "    print('p-value: {}'.format(result[1]))\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t{}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with substracting rolling mean\n",
    "rolling_mean = call_off_df_log.rolling(window=12).mean()\n",
    "df_log_minus_mean = call_off_df_log - rolling_mean\n",
    "df_log_minus_mean.dropna(inplace=True)\n",
    "get_stationarity(df_log_minus_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As p-value is below the threshold of 0.05 and ADF statistic is close to critical values, time series is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with applying exponential decay\n",
    "rolling_mean_exp_decay = call_off_df_log.ewm(halflife=12, min_periods=0, adjust=True).mean()\n",
    "df_log_exp_decay = call_off_df_log - rolling_mean_exp_decay\n",
    "df_log_exp_decay.dropna(inplace=True)\n",
    "get_stationarity(df_log_exp_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performed worse than substracting the rolling mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with time shifting\n",
    "call_off_df_log_shift = call_off_df_log - call_off_df_log.shift()\n",
    "call_off_df_log_shift.dropna(inplace=True)\n",
    "get_stationarity(call_off_df_log_shift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performed worse than subtracting the rolling mean. However, it is still more stationary than the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit to ARIMA - sample test with order = 1,1,1\n",
    "decomposition = seasonal_decompose(call_off_df_log) \n",
    "model = ARIMA(call_off_df_log, order=(1,1,1))\n",
    "results = model.fit(disp=-1)\n",
    "plt.plot(call_off_df_log_shift)\n",
    "plt.plot(results.fittedvalues, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare with original time series\n",
    "predictions_ARIMA_diff = pd.Series(results.fittedvalues, copy=True)\n",
    "predictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\n",
    "predictions_ARIMA_log = pd.Series(call_off_df_log['Calls_Offered'].iloc[0], index=call_off_df_log.index)\n",
    "predictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum, fill_value=0)\n",
    "predictions_ARIMA = np.exp(predictions_ARIMA_log)\n",
    "plt.plot(df)\n",
    "plt.plot(predictions_ARIMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with auto arima\n",
    "import pmdarima as pm\n",
    "from pmdarima.arima import auto_arima, ADFTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aft_test = ADFTest(alpha=0.05)\n",
    "aft_test.should_diff(call_off_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = y_to_train\n",
    "test = y_to_test\n",
    "plt.plot(train)\n",
    "plt.plot(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace(np.inf, np.nan).replace(-np.inf, np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_model = auto_arima(train.dropna(), start_p=0, d=1, start_q=0,\n",
    "                        max_p=5, max_d=5, max_q=5, start_P=0,\n",
    "                        D=1, start_Q=0, max_P=5, max_D=5,\n",
    "                        max_Q=5, m=12, seasonal=True,\n",
    "                        error_action='warn', trace=True,\n",
    "                        suppress_warnings=True, stepwise=True,\n",
    "                        random_state=20, n_fits=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test with auto_arima\n",
    "model_test = pm.auto_arima(train, seasonal=True, m=12)\n",
    "forecasts = model_test.predict(test.shape[0])\n",
    "\n",
    "x = np.arange(y.shape[0])\n",
    "plt.plot(x[:26], train, c='blue')\n",
    "plt.plot(x[26:], test, c='green')\n",
    "plt.plot(x[26:], forecasts, c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(arima_model.predict(n_periods=20), index=test.index)\n",
    "prediction.columns = ['predicted_calls_offered']\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
