{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEH Pharmacy Department"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Read and combine all excel tabs into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining all Excel sheets into one --Assuming all have the same headers, else append\n",
    "\n",
    "f = '../../Data/Pharmacy Dept/MEH TTO Data/MEH TTO Data.xlsx'\n",
    "df = pd.read_excel(f, sheet_name=None)\n",
    "df2 = pd.concat(df, ignore_index=True)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unnecessary columns\n",
    "df2.drop(['DurationOverdue', 'Item Type', 'Path', 'Weekday', 'TAT', 'Column1', 'Column2', 'Column3', 'Column4', 'TTODay', 'TTOWeek', 'Office Hours?', 'Office Hours', 'OfficeHours', 'TTOTAT'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Re-format of Columns and Data\n",
    "\n",
    "Concat same column headers (with different names) and append as new rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create Set 1 df with Apr, Nov, Dec 2021, Jan, Feb 2022 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#April, Nov, Dec 2021, Jan, Feb 2022\n",
    "\n",
    "df_set1 =  df2[df2['Date_x0028_Verified_x0029_'].notnull()]\n",
    "df_set1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Drop unnecessary columns that do not belong to Set 1 df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unnecessary columns that do not belong to set1\n",
    "\n",
    "df_set1.drop(['Date(Verified)', 'Date(Checked)', 'Date(Dispensing)', 'Date(PassedNurse)', 'Date(Pigeon)', 'Date(Pharm)', 'Date(Dispensed)', 'Time Verified', 'Case', 'TTOTimeIn'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_set1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Rename Columns for future standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Columns for future standardization\n",
    "set1_new_cols_name = {  'Date_x0028_Checked_x0029_': 'DateTime TTO Checked',\n",
    "                        'Date_x0028_Dispensed_x0029_': 'DateTime TTO Dispensed',\n",
    "                        'Date_x0028_Dispensing_x0029_': 'DateTime (Dispensing)',\n",
    "                        'Date_x0028_Verified_x0029_': 'DateTime TTO Received',\n",
    "                        'TTOWardIn': 'Ward',\n",
    "                        'Title': 'Case Number',\n",
    "                        'Date_x0028_Pharm_x0029_': 'DateTime (in Pharmacy)',\n",
    "                        'Date_x0028_Pigeon_x0029_': 'DateTime (in Pigeon)', \n",
    "                        'Date_x0028_NurseDispensed_x0029_': 'DateTime (Dispensed by Nurses)',\n",
    "                        'Date_x0028_PassedNurse_x0029_': 'DateTime (Passed to Nurse)'}\n",
    "\n",
    "df_set1.rename(columns=set1_new_cols_name, inplace=True)\n",
    "\n",
    "df_set1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Change DateTime ISO format to +08:00 for all relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_set1['DateTime TTO Checked'] = pd.to_datetime(df_set1['DateTime TTO Checked']).dt.tz_convert('Asia/Singapore').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_set1['DateTime TTO Dispensed'] = pd.to_datetime(df_set1['DateTime TTO Dispensed']).dt.tz_convert('Asia/Singapore').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_set1['DateTime (Dispensing)'] = pd.to_datetime(df_set1['DateTime (Dispensing)']).dt.tz_convert('Asia/Singapore').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_set1['DateTime TTO Received'] = pd.to_datetime(df_set1['DateTime TTO Received']).dt.tz_convert('Asia/Singapore').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_set1['DateTime (in Pharmacy)'] = pd.to_datetime(df_set1['DateTime (in Pharmacy)']).dt.tz_convert('Asia/Singapore').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_set1['DateTime (in Pigeon)'] = pd.to_datetime(df_set1['DateTime (in Pigeon)']).dt.tz_convert('Asia/Singapore').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_set1['DateTime (Dispensed by Nurses)'] = pd.to_datetime(df_set1['DateTime (Dispensed by Nurses)']).dt.tz_convert('Asia/Singapore').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_set1['DateTime (Passed to Nurse)'] = pd.to_datetime(df_set1['DateTime (Passed to Nurse)']).dt.tz_convert('Asia/Singapore').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_set1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Create Set 2 df with May, June, Aug 2021 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#May, June, Aug 2021\n",
    "\n",
    "df_set2 = df2[df2['Date(Verified)'].notnull() & df2['Case'].isnull()]\n",
    "df_set2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10: Remove unnecessary columns that do not belong to Set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_set2.drop(['Date_x0028_Checked_x0029_', 'Date_x0028_Dispensed_x0029_', 'Date_x0028_Dispensing_x0029_', 'Date_x0028_Verified_x0029_', 'TTOTimeIn', 'Date_x0028_Pharm_x0029_', 'Date_x0028_Pigeon_x0029_', 'Date_x0028_NurseDispensed_x0029_', 'Date_x0028_PassedNurse_x0029_', 'Case', 'Time Verified'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_set2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11: Rename Columns for future standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set2_new_cols_name = {  'TTOWardIn': 'Ward',\n",
    "                        'Title': 'Case Number',\n",
    "                        'Date(Verified)': 'DateTime TTO Received',\n",
    "                        'Date(Checked)': 'DateTime TTO Checked',\n",
    "                        'Date(Dispensing)': 'DateTime (Dispensing)',\n",
    "                        'Date(PassedNurse)': 'DateTime (Passed to Nurse)',\n",
    "                        'Date(Pigeon)': 'DateTime (in Pigeon)',\n",
    "                        'Date(Pharm)': 'DateTime (in Pharmacy)',\n",
    "                        'Date(Dispensed)': 'DateTime TTO Dispensed'}\n",
    "\n",
    "df_set2.rename(columns=set2_new_cols_name, inplace=True)\n",
    "\n",
    "df_set2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12: Change datetime64[ns] to object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_set2['DateTime TTO Received'] = df_set2['DateTime TTO Received'].astype(object)\n",
    "df_set2['DateTime TTO Checked'] = df_set2['DateTime TTO Checked'].astype(object)\n",
    "df_set2['DateTime (Dispensing)'] = df_set2['DateTime (Dispensing)'].astype(object)\n",
    "df_set2['DateTime (Passed to Nurse)'] = df_set2['DateTime (Passed to Nurse)'].astype(object)\n",
    "df_set2['DateTime (in Pigeon)'] = df_set2['DateTime (in Pigeon)'].astype(object)\n",
    "df_set2['DateTime (in Pharmacy)'] = df_set2['DateTime (in Pharmacy)'].astype(object)\n",
    "df_set2['DateTime TTO Dispensed'] = df_set2['DateTime TTO Dispensed'].astype(object)\n",
    "\n",
    "df_set2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: Create Set 3 df with Sept 2021 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_set3 = df2[df2['Date(Verified)'].notnull() & df2['Case'].notnull()]\n",
    "df_set3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 14: Remove unnecessary columns that do not belong to Set3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_set3.drop(['Date_x0028_Checked_x0029_', 'Date_x0028_Dispensed_x0029_', 'Date_x0028_Dispensing_x0029_', 'Date_x0028_Verified_x0029_', 'TTOTimeIn', 'Date_x0028_Pharm_x0029_', 'Date_x0028_Pigeon_x0029_', 'Date_x0028_NurseDispensed_x0029_', 'Date_x0028_PassedNurse_x0029_', 'Title', 'Time Verified'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_set3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 15: Rename Columns for future standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set3_new_cols_name = {  'TTOWardIn': 'Ward',\n",
    "                        'Case': 'Case Number',\n",
    "                        'Date(Verified)': 'DateTime TTO Received',\n",
    "                        'Date(Checked)': 'DateTime TTO Checked',\n",
    "                        'Date(Dispensing)': 'DateTime (Dispensing)',\n",
    "                        'Date(PassedNurse)': 'DateTime (Passed to Nurse)',\n",
    "                        'Date(Pigeon)': 'DateTime (in Pigeon)',\n",
    "                        'Date(Pharm)': 'DateTime (in Pharmacy)',\n",
    "                        'Date(Dispensed)': 'DateTime TTO Dispensed'}\n",
    "\n",
    "df_set3.rename(columns=set3_new_cols_name, inplace=True)\n",
    "\n",
    "df_set3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 16: Merge 3 Sets into dfinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal = pd.concat([df_set1, df_set2, df_set3]).reset_index()\n",
    "dfinal.drop('index', axis=1, inplace=True)\n",
    "\n",
    "dfinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 17: Export Re-format to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "dfinal.to_csv('../../Data/Pharmacy Dept/MEH TTO Data/MEH_TTO_Data_Merged.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 18: Read Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv for further cleaning\n",
    "dfinal_csv = pd.read_csv('../../Data/Pharmacy Dept/MEH TTO Data/MEH_TTO_Data_Merged.csv')\n",
    "dfinal_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_csv.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 19: Fix Data Type(s) for Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change all Time Column to datetime\n",
    "dfinal_csv['DateTime TTO Checked'] = pd.to_datetime(dfinal_csv['DateTime TTO Checked'], infer_datetime_format=True, errors='coerce')\n",
    "dfinal_csv['DateTime TTO Dispensed'] = pd.to_datetime(dfinal_csv['DateTime TTO Dispensed'], infer_datetime_format=True, errors='coerce')\n",
    "dfinal_csv['DateTime (Dispensing)'] = pd.to_datetime(dfinal_csv['DateTime (Dispensing)'], infer_datetime_format=True, errors='coerce')\n",
    "dfinal_csv['DateTime TTO Received'] = pd.to_datetime(dfinal_csv['DateTime TTO Received'], infer_datetime_format=True, errors='coerce')\n",
    "dfinal_csv['DateTime (in Pharmacy)'] = pd.to_datetime(dfinal_csv['DateTime (in Pharmacy)'], infer_datetime_format=True, errors='coerce')\n",
    "dfinal_csv['DateTime (in Pigeon)'] = pd.to_datetime(dfinal_csv['DateTime (in Pigeon)'], infer_datetime_format=True, errors='coerce')\n",
    "dfinal_csv['DateTime (Dispensed by Nurses)'] = pd.to_datetime(dfinal_csv['DateTime (Dispensed by Nurses)'], infer_datetime_format=True, errors='coerce')\n",
    "dfinal_csv['DateTime (Passed to Nurse)'] = pd.to_datetime(dfinal_csv['DateTime (Passed to Nurse)'], infer_datetime_format=True, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append 'Date' Column\n",
    "dfinal_csv['Date'] = dfinal_csv['DateTime TTO Received'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 20: Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfinal_cols_name = {'DateTime TTO Checked': 'Time TTO Checked',\n",
    "#                    'DateTime TTO Dispensed': 'Time (Dispensed)',\n",
    "#                    'DateTime (Dispensing)': 'Time (Dispensing)',\n",
    "#                    'DateTime TTO Received': 'Time TTO Received',\n",
    "#                    'DateTime (in Pharmacy)': 'Time (in Pharmacy)',\n",
    "#                    'DateTime (in Pigeon)': 'Time (in Pigeon)',\n",
    "#                    'DateTime (Dispensed by Nurses)': 'Time (Dispensed by Nurse)',\n",
    "#                    'DateTime (Passed to Nurse)': 'Time (Passed to Nurse)'}\n",
    "#\n",
    "#dfinal_csv.rename(columns=dfinal_cols_name, inplace=True)\n",
    "#\n",
    "#dfinal_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 21: Get Day of Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_csv['Weekday'] = pd.to_datetime(dfinal_csv['Date']).dt.day_name()\n",
    "\n",
    "#Assuming no NULL values in 'Date'\n",
    "dfinal_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time TTO Dispensed\n",
    "\n",
    "Disclaimer: Time TTO Dispensed Recalculation is not needed due to change in workflow (Based on Clarification call on 15/03)\n",
    "\n",
    "In due of various workflow conditions for MEH, re-calculation of Time TTO Dispensed is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSUMPTIONS\n",
    "#if dispensed by nurse -> time tto dispensed = time tto checked\n",
    "#if passed to nurse -> time tto dispensed = time tto checked\n",
    "#if in pigeon -> time tto dispensed = time tto checked\n",
    "#else time tto dispensed = time (dispensed)\n",
    "\n",
    "#dfinal_csv['Time TTO Dispensed'] = np.where(((dfinal_csv['Time (Dispensed by Nurse)'].notnull()) | \n",
    "#                                        (dfinal_csv['Time (Passed to Nurse)'].notnull()) | \n",
    "#                                        (dfinal_csv['Time (in Pigeon)'].notnull())), \n",
    "#                                        dfinal_csv['Time TTO Checked'], dfinal_csv['Time (Dispensed)'])\n",
    "#\n",
    "#dfinal_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfinal_csv[dfinal_csv['Time TTO Dispensed'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 22: Get Overall Time Taken (TAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASSUMPTIONS: Time TTO Dispensed is not null\n",
    "#if in Pharmacy -> total time taken = duration (Checked - Received) + duration (dispensed - dispensing)\n",
    "#else total time taken = duration (dispensed - received) --> INVALID after new workflow\n",
    "\n",
    "def duration(end, start):\n",
    "    difference = 0\n",
    "\n",
    "    difference = (pd.to_datetime(end.astype(str)) - pd.to_datetime(start.astype(str))).dt.total_seconds()/60\n",
    "    return difference\n",
    "\n",
    "dfinal_csv['TAT'] = np.where(dfinal_csv['DateTime TTO Dispensed'].notnull(),\n",
    "                                            (duration(dfinal_csv['DateTime TTO Checked'], dfinal_csv['DateTime TTO Received']) + duration(dfinal_csv['DateTime TTO Dispensed'], dfinal_csv['DateTime (Dispensing)'])),\n",
    "                                            #(duration(dfinal_csv['DateTime TTO Dispensed'], dfinal_csv['DateTime TTO Received']))\n",
    "                                            np.NaN)\n",
    "\n",
    "dfinal_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_csv[dfinal_csv['TAT'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 23: Create Meet KPI column with yes/no value\n",
    "\n",
    "MEH: Total Time Taken < 45mins = Yes, else: No."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_csv['Meet KPI'] = np.where((dfinal_csv['TAT'].isnull()), 'NA',\n",
    "                                    np.where((dfinal_csv['TAT'] <= (pd.to_datetime('00:45:00')).minute),\n",
    "                                            'Yes', 'No'))\n",
    "\n",
    "dfinal_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_csv[dfinal_csv['Meet KPI']==\"No\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 24: Create Office Hours column to check if case handled during offcie hours\n",
    "\n",
    "Standard Office Hours: 8:30AM to 5:00PM\n",
    "\n",
    "Taking into assumption that as long as Time TTO Dispensed is before 5:00PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_csv['Office Hours'] = np.where(  #dfinal_csv['Time TTO Received'].isnull() | \n",
    "                                        dfinal_csv['DateTime TTO Dispensed'].isnull() , 'NA', \n",
    "                                (np.where(  #(dfinal_csv['Time TTO Received'] >= pd.to_datetime('08:30:00').time()) & \n",
    "                                            (dfinal_csv['DateTime TTO Dispensed'].dt.time <= pd.to_datetime('17:00:00').time()),\n",
    "                                            'Yes', 'No')))\n",
    "\n",
    "dfinal_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_csv[dfinal_csv['Office Hours']==\"No\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 25: Calculate Time Taken for Nurses to Dispense\n",
    "\n",
    "Calculation for Staff Productivity Purposes\n",
    "\n",
    "Duration Difference of Passed to Nurse & Nurse Dispensed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking duration formula from Overall Time Taken (TAT) as ref to calculate\n",
    "dfinal_csv['Time Taken (Nurse to Dispense)'] = np.where((dfinal_csv['DateTime (Passed to Nurse)'].notnull() & dfinal_csv['DateTime (Dispensed by Nurses)'].notnull()),\n",
    "                                                        (duration(dfinal_csv['DateTime (Dispensed by Nurses)'], dfinal_csv['DateTime (Passed to Nurse)'])), np.NaN)\n",
    "\n",
    "dfinal_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to Seconds \n",
    "dfinal_csv['Time Taken (Nurse to Dispense)'] = dfinal_csv['Time Taken (Nurse to Dispense)']*60\n",
    "dfinal_csv[dfinal_csv['Time Taken (Nurse to Dispense)'].notnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Time Taken (Nurse to Dispense) to timedelta format to show  x days x hr x min x sec\n",
    "dfinal_csv['Time Taken (Nurse to Dispense)'] = pd.to_timedelta(dfinal_csv['Time Taken (Nurse to Dispense)'], 's')\n",
    "dfinal_csv[dfinal_csv['Time Taken (Nurse to Dispense)'].notnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 26: Create Average Time Taken from (Received to Checked) & (Checked to Dispensed) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Duration Difference of Received to Checked\n",
    "dfinal_csv['Time Taken (Received to Checked)'] = (dfinal_csv['DateTime TTO Checked'] - dfinal_csv['DateTime TTO Received'])\n",
    "#Get Duration Difference of Checked to Dispensed\n",
    "dfinal_csv['Time Taken (Checked to Dispensed)'] = (dfinal_csv['DateTime TTO Dispensed'] - dfinal_csv['DateTime TTO Checked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average time taken per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new dataframe to get results of Average Time Taken for each (Received to Checked) & (Checked to Dispensed)\n",
    "dfinal_avg_time = dfinal_csv[['Date', 'Time Taken (Received to Checked)', 'Time Taken (Checked to Dispensed)']]\n",
    "dfinal_avg_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert NaT to 00:00:00\n",
    "dfinal_avg_time.loc[dfinal_avg_time['Time Taken (Received to Checked)'].isnull(), 'Time Taken (Received to Checked)'] = pd.to_timedelta(0)\n",
    "dfinal_avg_time.loc[dfinal_avg_time['Time Taken (Checked to Dispensed)'].isnull(), 'Time Taken (Checked to Dispensed)'] = pd.to_timedelta(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get average time taken per day\n",
    "dfinal_avg_time = dfinal_avg_time.groupby(pd.to_datetime(dfinal_avg_time['Date']).dt.date).mean(numeric_only=False)\n",
    "dfinal_avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove miliseconds\n",
    "dfinal_avg_time['Time Taken (Received to Checked)'] = dfinal_avg_time['Time Taken (Received to Checked)'].dt.floor('s')\n",
    "dfinal_avg_time['Time Taken (Checked to Dispensed)'] = dfinal_avg_time['Time Taken (Checked to Dispensed)'].dt.floor('s')\n",
    "\n",
    "dfinal_avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename Columns\n",
    "dfinal_avg_time = dfinal_avg_time.rename({'Time Taken (Received to Checked)' : 'Avg Time Taken / Day (Received to Checked)', 'Time Taken (Checked to Dispensed)' : 'Avg Time Taken / Day (Checked to Dispensed)'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the results from grouby for Avg Time Taken\n",
    "dfinal_csv = dfinal_csv.merge(dfinal_avg_time, on='Date', how='left')\n",
    "dfinal_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace 00:00:00 in time columns with np.NaN\n",
    "dfinal_csv['Time Taken (Received to Checked)'] = dfinal_csv['Time Taken (Received to Checked)'].replace(pd.Timedelta(0), np.NaN)\n",
    "dfinal_csv['Time Taken (Checked to Dispensed)'] = dfinal_csv['Time Taken (Checked to Dispensed)'].replace(pd.Timedelta(0), np.NaN)\n",
    "dfinal_csv['Avg Time Taken / Day (Received to Checked)'] = dfinal_csv['Avg Time Taken / Day (Received to Checked)'].replace(pd.Timedelta(0), np.NaN)\n",
    "dfinal_csv['Avg Time Taken / Day (Checked to Dispensed)'] = dfinal_csv['Avg Time Taken / Day (Checked to Dispensed)'].replace(pd.Timedelta(0), np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average time taken per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_csv['Month']= pd.to_datetime(dfinal_csv['Date']).dt.month_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_avg_time = dfinal_csv[['Date', 'Time Taken (Received to Checked)', 'Time Taken (Checked to Dispensed)']]\n",
    "\n",
    "dfinal_avg_time['Month']= pd.to_datetime(dfinal_avg_time['Date']).dt.month_name()\n",
    "\n",
    "#Get average time taken per month\n",
    "dfinal_avg_time= dfinal_avg_time.groupby('Month').agg({'Time Taken (Received to Checked)': np.sum, 'Time Taken (Checked to Dispensed)': np.sum})\n",
    "\n",
    "x = dfinal_avg_time['Time Taken (Received to Checked)'] / np.timedelta64(1, 'm')\n",
    "y = dfinal_csv.groupby('Month')['Time Taken (Received to Checked)'].count()\n",
    "\n",
    "dfinal_avg_time['Avg Time Taken / Month (Received to Checked)'] = (x/y)\n",
    "\n",
    "dfinal_avg_time['Avg Time Taken / Month (Received to Checked)'] = pd.to_datetime(dfinal_avg_time['Avg Time Taken / Month (Received to Checked)'], unit='m').apply(lambda x: x.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = dfinal_avg_time['Time Taken (Checked to Dispensed)'] / np.timedelta64(1, 'm')\n",
    "b = dfinal_csv.groupby('Month')['Time Taken (Checked to Dispensed)'].count()\n",
    "\n",
    "dfinal_avg_time['Avg Time Taken / Month (Checked to Dispensed)'] = (a/b)\n",
    "\n",
    "dfinal_avg_time['Avg Time Taken / Month (Checked to Dispensed)'] = pd.to_datetime(dfinal_avg_time['Avg Time Taken / Month (Checked to Dispensed)'], unit='m').apply(lambda x: x.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_avg_time = dfinal_avg_time.drop(dfinal_avg_time.columns[[0, 1]], axis=1)\n",
    "\n",
    "dfinal_csv = dfinal_csv.merge(dfinal_avg_time, on='Month', how='left')\n",
    "\n",
    "dfinal_csv['Avg Time Taken / Month (Received to Checked)'] = pd.to_timedelta(dfinal_csv['Avg Time Taken / Month (Received to Checked)'])\n",
    "dfinal_csv['Avg Time Taken / Month (Checked to Dispensed)'] = pd.to_timedelta(dfinal_csv['Avg Time Taken / Month (Checked to Dispensed)'])\n",
    "dfinal_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 27: Calculate DateTime (in Pigeon) \n",
    "\n",
    "This calculation is for Power BI visualization of the No. of Cases that are needed to be placed in Pigeon. \n",
    "\n",
    "Calculate count = 1, if [DateTime (in Pigeon)] AND [DateTime TTO Dispensed] AND [DateTime (Dispensed by Nurse)] == np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_csv['Case in Pigeon?'] = np.where((dfinal_csv['DateTime (in Pigeon)'].notnull() &\n",
    "                                        dfinal_csv['DateTime TTO Dispensed'].isnull() & \n",
    "                                        dfinal_csv['DateTime (Dispensed by Nurses)'].isnull()), \n",
    "                                        1, 0)\n",
    "\n",
    "dfinal_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinal_csv[dfinal_csv['Case in Pigeon?']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 28: Export CLEANED to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "dfinal_csv.to_csv('../../Data/Pharmacy Dept/Data Cleaning/MEH_Data_Cleaned.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "082e9a3bcad0a290d0001e938aa60b99250c6c2ef33a923c00b70f9826caf4b7"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
